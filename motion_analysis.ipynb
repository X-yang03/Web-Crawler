{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup  #beatuisoup 解析html\n",
    "import requests                 #获取html\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#伪造agent\n",
    "user_agents=[\n",
    "    \"Mozilla/5.0 (Linux; U; Android 2.3.6; en-us; Nexus S Build/GRK39F) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1\",\n",
    "\t\"Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/532.5 (KHTML, like Gecko) Chrome/4.0.249.0 Safari/532.5\",\n",
    "\t\"Mozilla/5.0 (Windows; U; Windows NT 5.2; en-US) AppleWebKit/532.9 (KHTML, like Gecko) Chrome/5.0.310.0 Safari/532.9\",\n",
    "\t\"Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US) AppleWebKit/534.7 (KHTML, like Gecko) Chrome/7.0.514.0 Safari/534.7\",\n",
    "\t\"Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US) AppleWebKit/534.14 (KHTML, like Gecko) Chrome/9.0.601.0 Safari/534.14\",\n",
    "\t\"Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.14 (KHTML, like Gecko) Chrome/10.0.601.0 Safari/534.14\",\n",
    "\t\"Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.20 (KHTML, like Gecko) Chrome/11.0.672.2 Safari/534.20\",\n",
    "\t\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.27 (KHTML, like Gecko) Chrome/12.0.712.0 Safari/534.27\",\n",
    "\t\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/13.0.782.24 Safari/535.1\",\n",
    "\t\"Mozilla/5.0 (Windows NT 6.0) AppleWebKit/535.2 (KHTML, like Gecko) Chrome/15.0.874.120 Safari/535.2\",\n",
    "\t\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.7 (KHTML, like Gecko) Chrome/16.0.912.36 Safari/535.7\",\n",
    "\t\"Mozilla/5.0 (Windows; U; Windows NT 6.0 x64; en-US; rv:1.9pre) Gecko/2008072421 Minefield/3.0.2pre\",\n",
    "\t\"Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.10) Gecko/2009042316 Firefox/3.0.10\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36 Edg/118.0.2088.61\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建ip池，绕过反爬\n",
    "import random\n",
    "api_url = \"https://tps.kdlapi.com/api/gettps/?secret_id=-------&num=1&signature=--------&pt=1&sep=1\"\n",
    "#此处采用快代理的api接口，获取稳定的可用的ip\n",
    "proxy_ip = requests.get(api_url).text\n",
    "\n",
    "def getHtml(target_url):\n",
    "    username = '用户名'\n",
    "    password = '用户密码'\n",
    "    proxies = {\n",
    "    \"http\": \"http://%(user)s:%(pwd)s@%(proxy)s/\" % {\"user\": username, \"pwd\": password, \"proxy\": proxy_ip},\n",
    "    \"https\": \"http://%(user)s:%(pwd)s@%(proxy)s/\" % {\"user\": username, \"pwd\": password, \"proxy\": proxy_ip}\n",
    "    }#设置代理ip \n",
    "\n",
    "    while(True):\n",
    "        user_agent = random.choice(user_agents)\n",
    "        headers = {\n",
    "            'user-agent': user_agent\n",
    "        }\n",
    "        response = requests.get(url = target_url,headers=headers, proxies=proxies)\n",
    "\n",
    "        if response.status_code == 200:  #200 OK 成功获取网页\n",
    "            res = BeautifulSoup(response.text,'lxml')\n",
    "            if(\"中富电路\" in res.find(\"title\").text):  #如果出现中富，说明被封ip重定向\n",
    "                continue\n",
    "            return res\n",
    "        else:\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = getHtml(\"https://guba.eastmoney.com/list,200011.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPage(base_url,i):#获取某一页的帖子\n",
    "    All_data = []\n",
    "    url = base_url + str(i) + '.html' #拼接出网页地址\n",
    "    html = getHtml(url)                 #此处的html是函数中return的解析过的html\n",
    "    post_list=html.find_all('tr',class_ = 'listitem')\n",
    "    if post_list == []:             #得到的是空列表，当前页没有内容\n",
    "        return None\n",
    "    for post in post_list:\n",
    "        read_counts=post.find('div',class_='read').text       #获取帖子阅读数\n",
    "        comment_counts=post.find('div',class_='reply').text #获取帖子评论数\n",
    "        title=post.find('div',class_='title').text             #获取帖子标题    \n",
    "        time=post.find('div',class_='update').text              #获取更新时间\n",
    "        data = [read_counts,comment_counts,title,time]\n",
    "        All_data.append(data)\n",
    "    return All_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in range(1,1477): #用于测试600000的爬取\n",
    "    base_url = 'https://guba.eastmoney.com/list,600000_'\n",
    "    unit_result = getPage(base_url,i)\n",
    "    result.extend(unit_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result,columns=['read','comment','title','time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>read</th>\n",
       "      <th>comment</th>\n",
       "      <th>title</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117900</th>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>上海浦东发展银行股份有限公司第一届董事会第九次会议补充公告</td>\n",
       "      <td>08-08 12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117901</th>\n",
       "      <td>384</td>\n",
       "      <td>0</td>\n",
       "      <td>上海浦东发展银行股份有限公司召开2001年第一次临时股东大会公告</td>\n",
       "      <td>08-05 12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117902</th>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>上海浦东发展银行股份有限公司2001年中期报告</td>\n",
       "      <td>06-30 12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117903</th>\n",
       "      <td>361</td>\n",
       "      <td>0</td>\n",
       "      <td>上海浦东发展银行股份有限公司公告</td>\n",
       "      <td>04-06 12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117904</th>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>上海市联合律师事务所关于上海浦东发展银行股份有限公司2000年度</td>\n",
       "      <td>11-23 12:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       read comment                             title         time\n",
       "117900  128       0     上海浦东发展银行股份有限公司第一届董事会第九次会议补充公告  08-08 12:00\n",
       "117901  384       0  上海浦东发展银行股份有限公司召开2001年第一次临时股东大会公告  08-05 12:00\n",
       "117902  140       0           上海浦东发展银行股份有限公司2001年中期报告  06-30 12:00\n",
       "117903  361       0                  上海浦东发展银行股份有限公司公告  04-06 12:00\n",
       "117904  109       0  上海市联合律师事务所关于上海浦东发展银行股份有限公司2000年度  11-23 12:00"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./stock_a/600000.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来一段是对各个股票的爬取，耗时太大，不建议运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_a = pd.read_csv('./volume.CSV',low_memory=False,encoding = 'ANSI')\n",
    "code_list = []\n",
    "for item in stock_a.columns[1:]:\n",
    "    code_list.append(item.split('.')[0]) #获取股票代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_list = code_list[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4757"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(code_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapter(code):\n",
    "    base_url = 'https://guba.eastmoney.com/list,'+code+\"_\"\n",
    "    if code == '300814': #先跳过重定向页面\n",
    "        return None\n",
    "    result = []\n",
    "    for i in range(1,10000):\n",
    "        unit_result = getPage(base_url,i)\n",
    "        if(unit_result == None):\n",
    "            break #reach the end\n",
    "        result.extend(unit_result)\n",
    "    \n",
    "    df = pd.DataFrame(result,columns=['read','comment','title','time'])\n",
    "    path = './stock_a/'+code+'.csv'\n",
    "    df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code in code_list:\n",
    "    base_url = 'https://guba.eastmoney.com/list,'+code+\"_\"\n",
    "    if code == '300814': #先跳过重定向页面\n",
    "        continue\n",
    "    result = []\n",
    "    for i in range(1,10000):\n",
    "        unit_result = getPage(base_url,i)\n",
    "        if(unit_result == None):\n",
    "            break #reach the end\n",
    "        result.extend(unit_result)\n",
    "    \n",
    "    df = pd.DataFrame(result,columns=['read','comment','title','time'])\n",
    "    path = './stock_b/'+code+'.csv'\n",
    "    df.to_csv(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行到这"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83f0e803914e6688f4b135e83e4168da751805703b2ebb3db8669acb1320c6f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
